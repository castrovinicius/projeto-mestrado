{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinic\\anaconda3\\envs\\projeto-mestrado\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\vinic\\AppData\\Local\\Temp\\ipykernel_21372\\3664487231.py:14: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  from pandas_profiling import ProfileReport\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import optuna\n",
    "import torch\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from chart_studio import plotly\n",
    "\n",
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from optuna.visualization import plot_optimization_history, plot_contour, plot_param_importances\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, max_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    name_file, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == \".csv\":\n",
    "        data = pd.read_csv(file)\n",
    "    elif extension == \".xlsx\":\n",
    "        data = pd.read_excel(file)\n",
    "    \n",
    "    data = data.dropna()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_train_test(data, target, test_size=0.3, random_state=42):\n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    x = sc.fit_transform(data.drop([target], axis=1))\n",
    "    y = sc.fit_transform(data[target].values.reshape(-1,1))\n",
    "\n",
    "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fit_model(data, layer_config, optimizer, epochs=1000):\n",
    "    model = Sequential()\n",
    "\n",
    "    print(\"-\"*50)\n",
    "    print(f\"layer_config: {layer_config}\")\n",
    "    print(f\"optimizer: {optimizer}\")\n",
    "    print(f\"epochs: {epochs}\")\n",
    "\n",
    "    for layer in layer_config:\n",
    "        model.add(Dense(layer[0], activation=layer[1]))\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, mode=\"min\")\n",
    "\n",
    "    x_train, x_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "    start_time = time.time()\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, verbose=0, callbacks=[callback])\n",
    "    y_pred = model.predict(x_test)\n",
    "    stop_time = time.time()\n",
    "\n",
    "    print(\"-\"*50)\n",
    "    print(\"Training time:\", np.round((stop_time - start_time), 2),\"s\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"Accuracy score to {optimizer} & {layer}: {np.round(mean_squared_error(y_test, y_pred), 5)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(data, layer_config_list, optimizer_list, epochs_list):\n",
    "    for layer_config, optimizer, epochs in product(layer_config_list, optimizer_list, epochs_list):\n",
    "        print(\"-\"*50)\n",
    "        print(f\"layer_config: {layer_config}\")\n",
    "        print(f\"optimizer: {optimizer}\")\n",
    "        print(f\"epochs: {epochs}\")\n",
    "        \n",
    "        model = Sequential()\n",
    "        for layer in layer_config:\n",
    "            model.add(Dense(layer[0], activation=layer[1]))\n",
    "        \n",
    "        model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, mode=\"min\")\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "        start_time = time.time()\n",
    "        history = model.fit(x_train, y_train, epochs=epochs, verbose=0, callbacks=[callback])\n",
    "        y_pred = model.predict(x_test)\n",
    "        stop_time = time.time()\n",
    "\n",
    "        print(\"-\"*50)\n",
    "        print(\"Training time:\", np.round((stop_time - start_time), 2),\"s\")\n",
    "        print(\"-\"*50)\n",
    "        print(f\"Accuracy score: {np.round(mean_squared_error(y_test, y_pred), 5)}\")\n",
    "        print(\"\\n\"+\"=\"*50+\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ps1</th>\n",
       "      <th>Ps2</th>\n",
       "      <th>Ps3</th>\n",
       "      <th>Pd4</th>\n",
       "      <th>Pd5</th>\n",
       "      <th>Pd6</th>\n",
       "      <th>sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.848915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.839086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.832208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.827203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ps1  Ps2  Ps3       Pd4  Pd5       Pd6     sigma\n",
       "0  1.0  0.0  0.0  1.000000  0.0  0.000000  0.863621\n",
       "1  1.0  0.0  0.0  0.846154  0.0  0.153846  0.848915\n",
       "2  1.0  0.0  0.0  0.733333  0.0  0.266667  0.839086\n",
       "3  1.0  0.0  0.0  0.647059  0.0  0.352941  0.832208\n",
       "4  1.0  0.0  0.0  0.578947  0.0  0.421053  0.827203"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"\\Users\\vinic\\OneDrive\\UFSCar\\Dissertação\\Codigo\\data\\Caso1_230kV_0.9_1.1.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "layer_config: [(5, 'relu'), (1, 'linear')]\n",
      "optimizer: Adam\n",
      "epochs: 1000\n",
      "112/112 [==============================] - 0s 3ms/step\n",
      "--------------------------------------------------\n",
      "Training time: 10.9 s\n",
      "--------------------------------------------------\n",
      "Accuracy score to Adam & (1, 'linear'): 0.00361\n"
     ]
    }
   ],
   "source": [
    "df_step_2 = df_train_test(df, target='sigma')\n",
    "\n",
    "\n",
    "layer_config = [(5, \"relu\"), (1, \"linear\")]\n",
    "optimizer = \"Adam\"\n",
    "epochs = 1000\n",
    "\n",
    "create_fit_model(df_step_2, layer_config, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_config_list = [\n",
    "    [(5, \"relu\"), (1, \"linear\")],\n",
    "    [(10, \"relu\"), (1, \"linear\")]\n",
    "]\n",
    "\n",
    "optimizer_list = ['Adam', 'SGD']\n",
    "\n",
    "epochs_list = [100, 500]\n",
    "\n",
    "grid_search(df_step_2, layer_config_list, optimizer_list, epochs_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def objective(trial):\n",
    "\n",
    "    # Defina o número de unidades ocultas na camada oculta.\n",
    "    num_hidden_units = trial.suggest_int('num_hidden_units', 5, 10, log=True)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'sigmoid', 'tanh'])\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
    "\n",
    "    # Defina a arquitetura da rede neural.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_hidden_units, activation=activation))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile o modelo.\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, mode=\"min\")\n",
    "\n",
    "    # Treine o modelo.\n",
    "    model.fit(x_train, y_train, epochs=100, verbose=0, callbacks=[callback])\n",
    "\n",
    "    # Calcule o erro no conjunto de teste e retorne-a como a métrica a ser otimizada.\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = np.round(mean_squared_error(y_test, y_pred), 7)\n",
    "\n",
    "    results.append({'num_hidden_units': num_hidden_units, 'activation': activation, 'optimizer': optimizer, 'value': mse})\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = df_step_2[0], df_step_2[1], df_step_2[2], df_step_2[3]\n",
    "\n",
    "# Crie um estudo Optuna e execute a otimização.\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# Imprima os resultados.\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.sort_values('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto-mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 16:16:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "244974d43ddd5b9ea844f1207ef82e6a61e65d0b2a77978c2041a7809982dd03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
